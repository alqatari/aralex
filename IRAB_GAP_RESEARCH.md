# Research: Filling the Ø¥Ø¹Ø±Ø§Ø¨ (I'rab) Gap

## The Gap We Need to Fill

**What we have:** Morphological features (ROOT, POS, case markers like NOM/ACC/GEN, gender, number)

**What we need:** Full traditional Ø¥Ø¹Ø±Ø§Ø¨ like:
- Grammatical role labels: Ù…Ø¨ØªØ¯Ø£ØŒ Ø®Ø¨Ø±ØŒ ÙØ§Ø¹Ù„ØŒ Ù…ÙØ¹ÙˆÙ„ Ø¨Ù‡ØŒ Ø­Ø§Ù„ØŒ ØªÙ…ÙŠÙŠØ²
- Complete case analysis: "Ù…Ø±ÙÙˆØ¹ ÙˆØ¹Ù„Ø§Ù…Ø© Ø±ÙØ¹Ù‡ Ø§Ù„Ø¶Ù…Ø© Ø§Ù„Ø¸Ø§Ù‡Ø±Ø© Ø¹Ù„Ù‰ Ø¢Ø®Ø±Ù‡"
- Syntactic relationships: "ÙÙŠ Ù…Ø­Ù„ Ø±ÙØ¹ Ø®Ø¨Ø± Ø§Ù„Ù…Ø¨ØªØ¯Ø£"
- Dependency structure: which word depends on which

---

## Solution 1: Quranic Arabic Corpus Syntax Treebank

### Overview
- **Website:** https://corpus.quran.com/
- **GitHub:** https://github.com/kaisdukes/quranic-corpus
- **License:** GNU General Public License (Open Source)
- **Status:** 50% complete (as of latest update)

### What It Provides
âœ… **Dependency graphs** based on traditional Arabic Ø¥Ø¹Ø±Ø§Ø¨
âœ… **Syntactic treebank** with grammatical relationships
âœ… **Visual grammar diagrams** showing dependencies
âœ… **Traditional grammar concepts:**
  - Nominals: gender, adjectives, Ø¥Ø¶Ø§ÙØ©, apposition, ØªÙ…ÙŠÙŠØ²
  - Verbs: forms, subjects, objects, ÙƒØ§Ù† ÙˆØ£Ø®ÙˆØ§ØªÙ‡Ø§, moods
  - Particles: Ø¥ÙÙ†Ù‘ ÙˆØ£Ø®ÙˆØ§ØªÙ‡Ø§, Ø­Ø±Ù Ø¹Ø·Ù, vocatives, exceptives
  - Adverbials: Ø­Ø§Ù„ØŒ Ù…ÙØ¹ÙˆÙ„ Ù…Ø·Ù„Ù‚ØŒ Ù…ÙØ¹ÙˆÙ„ Ù„Ø£Ø¬Ù„Ù‡ØŒ Ù…ÙØ¹ÙˆÙ„ Ù…Ø¹Ù‡
  - Clauses: Ø´Ø±Ø· ÙˆØ¬ÙˆØ§Ø¨ Ø´Ø±Ø·, relative clauses

### Available Data
- **Download page:** https://corpus.quran.com/download/
- **Format:** XML (for treebank), TSV/text for morphology
- **Coverage:** 77,430 words
- **Version:** 0.4 (morphology complete, syntax 50% complete)

### Limitations
âŒ **Only 50% of syntax diagrams completed** - major gap!
âŒ **Unclear if full Ø¥Ø¹Ø±Ø§Ø¨ text is included** (might only be visual graphs)
âŒ **May not have detailed Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„Ø¥Ø¹Ø±Ø§Ø¨ explanations** in text form
âŒ **Requires email registration to download**

### How to Access
1. Visit https://corpus.quran.com/download/
2. Register with email
3. Download XML syntax treebank + morphology data
4. Parse XML to extract dependency relationships

---

## Solution 2: CAMeL Tools (Python Library)

### Overview
- **GitHub:** https://github.com/CAMeL-Lab/camel_tools
- **Organization:** NYU Abu Dhabi - CAMeL Lab
- **License:** MIT (Open Source)
- **Latest:** Camel Morph MSA (2024) - presented at LREC-COLING 2024

### What It Provides
âœ… **Morphological analysis** (100K+ lemmas, 1.45B analyses)
âœ… **CamelParser** - dependency parsing with syntactic case
âœ… **Diacritization** with case assignment rules
âœ… **NER, Sentiment Analysis, Dialect ID**

### Capabilities
- **Dependency parsing** aligned with morphological features
- **Syntactic case analysis** (improving diacritization through syntax)
- **Agreement rules** for case and state
- **Modern Standard Arabic + Classical Arabic features**

### Limitations
âŒ **NOT pre-trained on Quran specifically** (general MSA)
âŒ **Generates predictions**, not gold-standard annotations
âŒ **May not match traditional Ø¥Ø¹Ø±Ø§Ø¨ exactly** (computational vs. traditional)
âŒ **Requires Python integration** (you're using Haskell/Purescript)
âŒ **No "full sentence Ø¥Ø¹Ø±Ø§Ø¨ text"** - outputs structured features

### How to Use
```python
pip install camel-tools

from camel_tools.morphology.database import MorphologyDB
from camel_tools.disambig.mle import MLEDisambiguator
from camel_tools.parsers.camel_parser import CamelParser

# Load parser
parser = CamelParser.pretrained()

# Parse sentence
result = parser.parse(sentence)
# Returns dependency tree with morphological features
```

---

## Solution 3: Stanza (Stanford NLP)

### Overview
- **Website:** https://stanfordnlp.github.io/stanza/
- **Organization:** Stanford NLP Group
- **License:** Apache 2.0 (Open Source)
- **Languages:** 70+ including Arabic

### What It Provides
âœ… **Universal Dependencies** parsing (standard format)
âœ… **Tokenization, lemmatization, POS tagging**
âœ… **Dependency parsing** with syntactic relations
âœ… **Morphological features** (gender, case, number, etc.)

### Arabic Models
- Trained on **Universal Dependencies Arabic corpora**
- Supports **Modern Standard Arabic**
- Uses **PADT treebank** (Prague Arabic Dependency Treebank)

### Limitations
âŒ **NOT Quran-specific** (general MSA/news text)
âŒ **Universal Dependencies â‰  Traditional Arabic Grammar**
  - UD uses labels like `nsubj`, `obj`, `obl`
  - Traditional uses Ù…Ø¨ØªØ¯Ø£ØŒ Ø®Ø¨Ø±ØŒ ÙØ§Ø¹Ù„ØŒ Ù…ÙØ¹ÙˆÙ„ Ø¨Ù‡
âŒ **No full Ø¥Ø¹Ø±Ø§Ø¨ text generation**
âŒ **Requires Python** (same issue as CAMeL)

### How to Use
```python
import stanza

# Download Arabic model
stanza.download('ar')
nlp = stanza.Pipeline('ar')

# Parse
doc = nlp(text)
for sentence in doc.sentences:
    print(sentence.dependencies)
    # Returns UD-style dependency tuples
```

---

## Solution 4: Traditional Ø¥Ø¹Ø±Ø§Ø¨ Books (Digitized)

### Overview
Multiple complete Ø¥Ø¹Ø±Ø§Ø¨ Ø§Ù„Ù‚Ø±Ø¢Ù† books are available as **digitized PDFs** on Internet Archive

### Available Books
1. **"Ø¥Ø¹Ø±Ø§Ø¨ Ø§Ù„Ù‚Ø±Ø¢Ù† ÙˆØ¨ÙŠØ§Ù†Ù‡"** - Ù…Ø­ÙŠÙŠ Ø§Ù„Ø¯ÙŠÙ† Ø§Ù„Ø¯Ø±ÙˆÙŠØ´
   - URL: https://archive.org/details/5_20200604_20200604_0241
   - Complete traditional Ø¥Ø¹Ø±Ø§Ø¨ for entire Quran
   
2. **"Ø¥Ø¹Ø±Ø§Ø¨ Ø§Ù„Ù‚Ø±Ø¢Ù† Ø§Ù„ÙƒØ±ÙŠÙ…"** - Ø¯Ø§Ø± Ø§Ù„ØµØ­Ø§Ø¨Ø© Ù„Ù„ØªØ±Ø§Ø«
   - URL: https://archive.org/details/erabquran_sahaba
   - Scholarly traditional Ø¥Ø¹Ø±Ø§Ø¨
   
3. **"Ø§Ù„Ø¬Ø¯ÙˆÙ„ ÙÙŠ Ø¥Ø¹Ø±Ø§Ø¨ Ø§Ù„Ù‚Ø±Ø¢Ù† ÙˆØµØ±ÙÙ‡ ÙˆØ¨ÙŠØ§Ù†Ù‡"** - Ù…Ø­Ù…ÙˆØ¯ ØµØ§ÙÙŠ
   - URL: https://archive.org/details/Eidh416_gmail_01_201801
   - Size: 3.4GB (comprehensive)
   - Tables format (easier to parse?)
   
4. **"Ø¥Ø¹Ø±Ø§Ø¨ Ø§Ù„Ù‚Ø±Ø¢Ù† Ø§Ù„ÙƒØ±ÙŠÙ…"** - Ø¯. Ù…Ø­Ù…ÙˆØ¯ Ø³Ù„ÙŠÙ…Ø§Ù† ÙŠØ§Ù‚ÙˆØª
   - URL: https://archive.org/details/Eidh416_gmail_20180122_1018

### What They Provide
âœ… **Complete traditional Ø¥Ø¹Ø±Ø§Ø¨** for every word
âœ… **Full explanations** like "Ø§Ø³Ù… Ø¥Ø´Ø§Ø±Ø© Ù…Ø¨Ù†ÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙƒÙˆÙ† ÙÙŠ Ù…Ø­Ù„ Ø±ÙØ¹ Ù…Ø¨ØªØ¯Ø£"
âœ… **Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„Ø¥Ø¹Ø±Ø§Ø¨** details
âœ… **Syntactic relationships** explained
âœ… **Covers 100% of Quran** (not 50%)

### Limitations
âŒ **PDF format** - requires OCR to extract
âŒ **Unstructured text** - needs parsing/alignment with verses
âŒ **Manual digitization work required**
âŒ **No machine-readable format** (not JSON/XML)
âŒ **OCR errors** (especially with Arabic diacritics)

### How to Use
1. Download PDFs from Internet Archive
2. OCR with Arabic support (Tesseract, Adobe Acrobat)
3. Parse text to extract Ø¥Ø¹Ø±Ø§Ø¨ per word
4. Align with Quranic text (verse:word matching)
5. Store in database as structured data

---

## Comparison Matrix

| Solution | Coverage | Format | Traditional Ø¥Ø¹Ø±Ø§Ø¨ | Ready to Use | Integration |
|----------|----------|--------|-------------------|--------------|-------------|
| **Quranic Corpus Treebank** | 50% | XML | Partial | âš ï¸ Partial | Medium |
| **CAMeL Tools** | 100% | Computed | No (UD-style) | âœ… Yes | Hard (Python) |
| **Stanza** | 100% | Computed | No (UD-style) | âœ… Yes | Hard (Python) |
| **Traditional Books** | 100% | PDF | âœ… Full | âŒ No | Very Hard (OCR) |

---

## Recommended Approach

### Short Term (Use What Works Now):
**Option A: Corpus Treebank (50% coverage)**
- Download XML from corpus.quran.com
- Parse dependency relationships
- Map to traditional grammar terms where available
- Accept 50% coverage limitation

**Option B: Expand Existing Morphology**
- Use your current morphology data
- Write Haskell rules to infer grammatical roles from:
  - POS tags + case markers â†’ likely role (NOM after DEM = Ù…Ø¨ØªØ¯Ø£)
  - Verb + NOM noun = likely ÙØ§Ø¹Ù„
  - Verb + ACC noun = likely Ù…ÙØ¹ÙˆÙ„ Ø¨Ù‡
- Generate "partial Ø¥Ø¹Ø±Ø§Ø¨" programmatically
- Less accurate but covers 100%

### Long Term (Complete Solution):
**Option C: Digitize Traditional Ø¥Ø¹Ø±Ø§Ø¨**
1. Download "Ø§Ù„Ø¬Ø¯ÙˆÙ„ ÙÙŠ Ø¥Ø¹Ø±Ø§Ø¨ Ø§Ù„Ù‚Ø±Ø¢Ù†" (table format = easier)
2. OCR with Tesseract Arabic
3. Write Haskell parser to extract structured data:
   ```
   Verse 2:2, Word 1 (Ø°Ù„Ùƒ):
   - Role: Ù…Ø¨ØªØ¯Ø£
   - Case: Ù…Ø±ÙÙˆØ¹
   - Reason: Ø§Ø³Ù… Ø¥Ø´Ø§Ø±Ø© Ù…Ø¨Ù†ÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙƒÙˆÙ† ÙÙŠ Ù…Ø­Ù„ Ø±ÙØ¹
   ```
4. Store in `aralex.db` new table: `irab_details`
5. Display in frontend grammar panel

**Hybrid: Corpus Treebank (50%) + Generated Rules (50%)**
- Use treebank where available (high quality)
- Generate from rules for remaining verses
- Flag which is which to user

---

## Technical Recommendation

**For Aralex specifically, I recommend:**

### Phase 1 (Immediate - 2 weeks):
âœ… Download Quranic Corpus XML syntax treebank
âœ… Parse dependency graphs to extract grammatical roles
âœ… Map UD-style relations to Arabic terms (if needed)
âœ… Add to database for 50% of verses
âœ… Show in UI: "Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Ø­ÙˆÙŠ Ù…ØªØ§Ø­ Ù„Ù€ 50% Ù…Ù† Ø§Ù„Ø¢ÙŠØ§Øª"

### Phase 2 (Medium term - 1-2 months):
âœ… Write Haskell grammar rules for common patterns:
  - Nominal sentences (Ø¬Ù…Ù„Ø© Ø§Ø³Ù…ÙŠØ©)
  - Verbal sentences (Ø¬Ù…Ù„Ø© ÙØ¹Ù„ÙŠØ©)
  - Particle sentences (Ø¬Ù…Ù„Ø© Ø­Ø±ÙÙŠØ©)
âœ… Infer grammatical roles from morphology + context
âœ… Cover remaining 50% with "inferred" label
âœ… Show in UI: "Ù…Ø­Ø³ÙˆØ¨ Ø¢Ù„ÙŠØ§Ù‹" vs "Ù…Ù† Ø§Ù„Ù…Ø¯ÙˆÙ†Ø© Ø§Ù„Ù„ØºÙˆÙŠØ©"

### Phase 3 (Long term - 3-6 months):
âœ… OCR one traditional Ø¥Ø¹Ø±Ø§Ø¨ book ("Ø§Ù„Ø¬Ø¯ÙˆÙ„" recommended)
âœ… Parse and align with verse:word positions
âœ… Validate against existing data
âœ… Replace inferred data with gold-standard
âœ… Achieve 100% coverage with traditional Ø¥Ø¹Ø±Ø§Ø¨

---

## Python Integration (If Chosen)

If you decide to use CAMeL Tools or Stanza:

### Architecture:
```
Haskell Backend (Port 8080)
    â†“ HTTP call
Python Microservice (Port 8081)
    â†“ Uses CAMeL/Stanza
Returns JSON with irab features
    â†“
Haskell parses and stores in DB
```

### Python Service:
```python
from flask import Flask, request, jsonify
from camel_tools.parsers.camel_parser import CamelParser

app = Flask(__name__)
parser = CamelParser.pretrained()

@app.route('/parse', methods=['POST'])
def parse_text():
    text = request.json['text']
    result = parser.parse(text)
    return jsonify(result.to_dict())

if __name__ == '__main__':
    app.run(port=8081)
```

### Haskell Client:
```haskell
import Network.HTTP.Simple

callPythonParser :: Text -> IO ParseResult
callPythonParser text = do
  let request = setRequestBodyJSON (object ["text" .= text])
              $ parseRequest_ "POST http://localhost:8081/parse"
  response <- httpJSON request
  pure $ getResponseBody response
```

---

## Final Verdict

**Best solution for Aralex:**

ðŸ¥‡ **Primary: Quranic Corpus XML Treebank** (50% coverage, authoritative)
ðŸ¥ˆ **Secondary: Rule-based inference** (cover remaining 50%, marked as computed)
ðŸ¥‰ **Future: OCR traditional books** (100% gold-standard when resources allow)

**Avoid:**
- âŒ CAMeL/Stanza for now (adds Python dependency, not Quran-specific)
- âŒ Manual entry (too time-consuming)

**The gap CAN be filled**, but requires combining:
1. Existing corpus data (partial)
2. Programmatic rules (intermediate)
3. Traditional scholarship digitization (complete)
